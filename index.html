<!DOCTYPE html>
<html lang="en-US">

<head>
  <title> Kazuki Osawa </title>
  <meta charset="utf-8">
  <meta name="description" content="Kazuki Osawa's homepage">
  <link href="style.css" rel="stylesheet" type="text/css">
  <link rel="shortcut icon" href="tokyotechlogo.ico">
</head>

<body>
  <div>
    <table align="center">
      <tbody>
        <tr>
            <td width="55%">
              <div>
                <h1>Kazuki Osawa / 大沢 和樹</h1>
              </div>
              <p>
                School of Computing, Tokyo Institute of Technology, JAPAN <br>
                Institute for Infocomm Research (I²R), A*STAR, SINGAPORE <br>
                東京工業大学 情報理工学院<br>
                シンガポール科学技術研究庁 インフォコム研究所<br>
                <!-- 
                <br>
                Research Fellow of Japan Society for the Promotion of Science <br>
                日本学術振興会 特別研究員DC <br>
                -->
                <br>
                Email: oosawa.k.ad at m dot titech dot ac dot jp
                <br>
                <a href="https://scholar.google.com/citations?user=IHdZHh8AAAAJ&hl=en">Google Scholar</a>
              </p>
            </td>
            <td width="45%">
                <figure>
                    <img src="./kazukiosawa_taki.jpg" width="100%">
                    <figcaption class="prof" align="center">Photo by Yuichiro Ueno @ 浄蓮の滝</figcaption>
                </figure>
            </td>
        </tr>
      </tbody>
    </table>

    <hr>
    <h2>About Me</h2>   
    <p>
    I am a Ph.D. candidate in the Department of Computer Science, School of Computing, Tokyo Institute of Technology, supervised by <a href="http://www.rio.gsic.titech.ac.jp/en/member/yokota.html">Rio Yokota</a>.
    I am now working as a Research Assistant at the <a href="https://www.a-star.edu.sg/i2r">Institute for Infocomm Research (I²R )</a>, A*STAR, advised by <a href="http://ai.stanford.edu/~csfoo/">Chuan-Sheng Foo</a> and <a href="http://vijaychan.github.io/">Vijay Chandrasekhar</a>.
    <!--
    I am a <a href="https://www.jsps.go.jp/english/e-pd/index.html">Research Fellow of Japan Society for the Promotion of Science (JSPS)</a> (DC).
    -->
    </p>

    <ul>
        <li>10/2018 - present: Research Assistant at the Institute for Infocomm Research (I²R), A*STAR</li>
        <li>4/2018 - present: Ph.D. candidate in the Department of Computer Science at the Tokyo Institute of Technology</li>
        <li>4/2016 - 3/2018: M.Eng. in the Department of Computer Science at the Tokyo Institute of Technology</li>
        <li>4/2012 - 3/2016: B.Eng. in the Department of Computer Science at the Tokyo Institute of Technology</li>
    </ul>

    <h2>Research Interests</h2>
    <p>My research interests include optimization, approximation theory, high-performance computing (HPC), and deep learning.
    My goal in the Ph.D. course is to propose theoretical optimization methods for deep neural networks which are compatible with research in the HPC field and to become a bridge between these fields.</p>
    <p>Topics:</p>
    <ul>
      <li>Second-order optimization methods for deep learning</li>
      <li>Large-scale distributed computing</li>
      <li>Bayesian deep learning</li>
      <li>Continual learning</li>
    </ul>

    <h2>Preprints</h2>
    <ul>
      <li>
          <a href="https://arxiv.org/abs/1811.12019">Large-scale Distributed Second-order Optimization Using Kronecker-factored Approximate Curvature for Deep Convolutional Neural Networks</a>,
          <br>
          <b>Kazuki Osawa</b>, Yohei Tsuji, Yuichiro Ueno, Akira Naruse, Rio Yokota, and Satoshi Matsuoka,
          <br>
          arXiv:1811.12019 [cs.LG], Nov. 2018. <strong class="red">Accepted at CVPR'19, Long Beach, CA</strong> (AR:25.2% 1300/5160)
      </li>
    </ul>

    <h2>Publications</h2>
    <ul>
      <li>
          <a href="https://link.springer.com/chapter/10.1007/978-3-319-68612-7_52">Evaluating the Compression Efficiency of the Filters in Convolutional Neural Networks</a>,
          <br>
          <b>Kazuki Osawa</b> and Rio Yokota,
          <br>
          Artificial Neural Networks and Machine Learning – ICANN 2017, pp 459-466, Springer 2017.
      </li>
      <li>
          <a href="https://ieeexplore.ieee.org/document/8035076">Accelerating Matrix Multiplication in Deep Learning by Using Low-Rank Approximation</a>,
          <br>
          <b>Kazuki Osawa</b>, Akira Sekiya, Hiroki Naganuma, and Rio Yokota,
          <br>
          2017 International Conference on High Performance Computing & Simulation (HPCS), pp 186-192, IEEE 2017.
      </li>
    </ul>

    <h2>Blog Posts</h2>
    <ul>
        <li>
            <a href="https://medium.com/@osawa1021/introducing-k-fac-and-its-application-for-large-scale-deep-learning-4e3f9b443414">Introducing K-FAC — A Second-Order Optimization Method for Large-Scale Deep Learning</a>,
            <br>
            Dec. 2018 (Towards Data Science, Medium)
        </li>
        <li>
            <a href="https://medium.com/@osawa1021/k-fac%E3%81%A8%E3%81%AF-de30537f7096">K-FACとは？〜大規模深層学習のための二次最適化の実現〜</a>,
            <br>
            Dec. 2018 (Medium)
        </li>
    </ul>

    <h2>CV</h2>
    My CV can be found <a href="./kazukiosawa_cv.pdf">here</a>. (Last updated: Jan 2019)

  </div>
</body>

</html>
